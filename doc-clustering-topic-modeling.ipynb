{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_vocab(vocab_file_name):\n",
    "\treturn [w.strip() for w in open(vocab_file_name)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read docword.txt into a document x word matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_docword(file_name):\n",
    "\n",
    "\tfile_handle = open(file_name)\n",
    "\treader = csv.reader(file_handle, delimiter=' ')\n",
    "\tD = int(next(reader)[0])\n",
    "\tW = int(next(reader)[0])\n",
    "\tN = int(next(reader)[0])\n",
    "\n",
    "\t#create DxW numpy matrix\n",
    "\tm = np.empty(shape=[D,W], dtype='int32')\n",
    "\t#instead of creating a sparse matrix and then fill it up, create a numpy matrix\n",
    "\t#and then later convert it to csr -> SparseEfficiencyWarning\n",
    "\t#m = sparse.csr_matrix( (D,W), dtype='int8')\n",
    "\n",
    "\tfor row in reader:\n",
    "\t\tD_i = int(row[0])-1\n",
    "\t\tW_i = int(row[1])-1\n",
    "\t\tcount = int(row[2])\n",
    "\t\tm[D_i, W_i] = count\n",
    "\n",
    "\tm = sparse.csr_matrix(m)\n",
    "\n",
    "\treturn m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docword = read_docword(file_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "term frequency inverse document frequency\n",
    "it's a more reliable metric than plain frequency bc it normalizes frequency across documents\n",
    "very common (and semantically meaningless) words like articles ('the', 'a', 'an' ...), prepositions, etc... are in this way given less weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "docword_tfidf = tfidf_transformer.fit_transform(docword)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix_1third = docword_tfidf.shape[0]/3\n",
    "docword_tfidf_test = docword_tfidf[0:ix_1third,]\n",
    "docword_tfidf_train = docword_tfidf[ix_1third+1:,]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbayes_classifier = MultinomialNB().fit(docword_tfidf_test, docword_tfidf_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
